set debug true
adjust
fusions --scale8

nodeoption GRU_74 RNN_STATES_AS_INPUTS 1
nodeoption GRU_136 RNN_STATES_AS_INPUTS 1

#run_pyscript model/nntool_scripts/collect_stats.py samples/quant/ 8 $(GRU) $(MODEL_BUILD)/ $(H_STATE_LEN)
#aquant --stats $(MODEL_BUILD)/data_quant.json

#qtune --step * clip_type=none
##qtune --step h_state_GRU_74 clip_type=none
##qtune --step h_state_GRU_136 clip_type=none
##qtune --step GRU_74 clip_type=none
##qtune --step GRU_136 clip_type=none
#qtune --step input_1 scheme=float float_type=float16 
#qtune --step Conv_0_reshape_in scheme=float float_type=float16 
#qtune --step Conv_0_fusion scheme=float float_type=float16 
#qtune --step Conv_139_fusion scheme=float float_type=float16 
#qtune --step Conv_142_fusion scheme=float float_type=float16 
#qtune --step Conv_142_reshape_out scheme=float float_type=float16 
#qtune --step Sigmoid_143 scheme=float float_type=float16 
##qtune --step 39 scheme=float float_type=float16 
#qtune --step output_1 scheme=float float_type=float16 

## uncomment this for higher accuracy
fquant
qtune --step * scheme=float float_type=float16


qshow

set l3_ram_ext_managed true
set l3_flash_device $(MODEL_L3_FLASH)
set l3_ram_device $(MODEL_L3_RAM)

set graph_reorder_constant_in true
set graph_produce_node_names true
set graph_produce_operinfos true
set graph_monitor_cycles true
set graph_const_exec_from_flash $(EXEC_FROM_FLASH)

#set graph_async_fork true
#set graph_group_weights true


#set graph_dump_tensor 7
#set graph_trace_exec true

save_state
